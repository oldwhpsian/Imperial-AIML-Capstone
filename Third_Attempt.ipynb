{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "287e1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes_functions import (BlackBoxFunction, import_weekly_queries_results, \n",
    "    save_all_data, backup_all_data, make_mesh)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b34ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_1 = BlackBoxFunction('function_1')\n",
    "function_2 = BlackBoxFunction('function_2')\n",
    "function_3 = BlackBoxFunction('function_3')\n",
    "function_4 = BlackBoxFunction('function_4')\n",
    "function_5 = BlackBoxFunction('function_5')\n",
    "function_6 = BlackBoxFunction('function_6')\n",
    "function_7 = BlackBoxFunction('function_7')\n",
    "function_8 = BlackBoxFunction('function_8')\n",
    "\n",
    "all_bbox_functions = [function_1, function_2, function_3, function_4, function_5, function_6, function_7, function_8]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "849c9bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries, results = import_weekly_queries_results(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14478c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\John\\Desktop\\Capstone for GitHub\\Imperial-AIML-Capstone\\classes_functions.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.data = self.data.append(to_append, ignore_index=True)\n",
      "C:\\Users\\John\\Desktop\\Capstone for GitHub\\Imperial-AIML-Capstone\\classes_functions.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.data = self.data.append(to_append, ignore_index=True)\n",
      "C:\\Users\\John\\Desktop\\Capstone for GitHub\\Imperial-AIML-Capstone\\classes_functions.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.data = self.data.append(to_append, ignore_index=True)\n",
      "C:\\Users\\John\\Desktop\\Capstone for GitHub\\Imperial-AIML-Capstone\\classes_functions.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.data = self.data.append(to_append, ignore_index=True)\n",
      "C:\\Users\\John\\Desktop\\Capstone for GitHub\\Imperial-AIML-Capstone\\classes_functions.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.data = self.data.append(to_append, ignore_index=True)\n",
      "C:\\Users\\John\\Desktop\\Capstone for GitHub\\Imperial-AIML-Capstone\\classes_functions.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.data = self.data.append(to_append, ignore_index=True)\n",
      "C:\\Users\\John\\Desktop\\Capstone for GitHub\\Imperial-AIML-Capstone\\classes_functions.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.data = self.data.append(to_append, ignore_index=True)\n",
      "C:\\Users\\John\\Desktop\\Capstone for GitHub\\Imperial-AIML-Capstone\\classes_functions.py:48: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.data = self.data.append(to_append, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# # ''' Loop that will add the weeks queries to the data in the function objects then save the data'''\n",
    "# # ''' Only run this cell once per week.'''\n",
    "# for query, result, function in zip(queries, results, all_bbox_functions):\n",
    "#     function.add_query(query, result)\n",
    "#     function.export_data_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9ace84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_1 done.\n",
      "function_2 done.\n",
      "function_3 done.\n",
      "function_4 done.\n",
      "function_5 done.\n",
      "function_6 done.\n",
      "function_7 done.\n",
      "function_8 done.\n"
     ]
    }
   ],
   "source": [
    "length_scale = 0.01\n",
    "UCB_queries = []\n",
    "PI_queries = []\n",
    "for function in all_bbox_functions:\n",
    "    function.localize(0.05, function.sample_density)\n",
    "    function.fit_GP_model(length_scale, beta=1)\n",
    "    function.predict()\n",
    "    UCB_queries.append(function.UCB_prediction_lst)\n",
    "    PI_queries.append(function.PI_prediction_lst)\n",
    "    print(function.name + ' done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d93acd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI:   [False, False, False, False, False, False, False, False] \n",
      "UCB:  [False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "redundant_PI = [f.redundant_PI for f in all_bbox_functions]\n",
    "redundant_UCB = [f.redundant_UCB for f in all_bbox_functions]\n",
    "print('PI:  ', redundant_PI, '\\nUCB: ', redundant_UCB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72406bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618468-0.628478\n",
      "0.716578-0.429259\n",
      "0.575546-0.322602-0.533926\n",
      "0.572664-0.423670-0.420724-0.245946\n",
      "0.256122-0.888775-0.909183-0.827550\n",
      "0.678186-0.104693-0.682552-0.643997-0.006401\n",
      "0.186042-0.247156-0.396508-0.223551-0.368842-0.856391\n",
      "0.047373-0.090047-0.213423-0.014675-0.270007-0.353847-0.318406-0.822396\n",
      "\n",
      "UCB: \n",
      "0.618468-0.629378\n",
      "0.715977-0.429860\n",
      "0.590622-0.337677-0.549002\n",
      "0.527766-0.378772-0.375826-0.199007\n",
      "0.307142-0.937755-0.955518-0.880611\n",
      "0.678186-0.104693-0.682552-0.643997-0.006401\n",
      "0.186042-0.247156-0.396508-0.223551-0.368842-0.856391\n",
      "0.047373-0.090047-0.213423-0.014675-0.270007-0.353847-0.318406-0.822396\n"
     ]
    }
   ],
   "source": [
    "for f in all_bbox_functions:\n",
    "    print(f.PI_prediction_str)\n",
    "\n",
    "print('\\nUCB: ')\n",
    "for f in all_bbox_functions:\n",
    "    print(f.UCB_prediction_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b05356d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_1</th>\n",
       "      <th>X_2</th>\n",
       "      <th>X_3</th>\n",
       "      <th>Y</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.171525</td>\n",
       "      <td>0.343917</td>\n",
       "      <td>0.248737</td>\n",
       "      <td>-0.112122</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.242114</td>\n",
       "      <td>0.644074</td>\n",
       "      <td>0.272433</td>\n",
       "      <td>-0.087963</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.534906</td>\n",
       "      <td>0.398501</td>\n",
       "      <td>0.173389</td>\n",
       "      <td>-0.111415</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.492581</td>\n",
       "      <td>0.611593</td>\n",
       "      <td>0.340176</td>\n",
       "      <td>-0.034835</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.134622</td>\n",
       "      <td>0.219917</td>\n",
       "      <td>0.458206</td>\n",
       "      <td>-0.048008</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.345523</td>\n",
       "      <td>0.941360</td>\n",
       "      <td>0.269363</td>\n",
       "      <td>-0.110621</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.151837</td>\n",
       "      <td>0.439991</td>\n",
       "      <td>0.990882</td>\n",
       "      <td>-0.398926</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.645503</td>\n",
       "      <td>0.397143</td>\n",
       "      <td>0.919771</td>\n",
       "      <td>-0.113869</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.746912</td>\n",
       "      <td>0.284196</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>-0.131461</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.170477</td>\n",
       "      <td>0.697032</td>\n",
       "      <td>0.149169</td>\n",
       "      <td>-0.094190</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.220549</td>\n",
       "      <td>0.297825</td>\n",
       "      <td>0.343555</td>\n",
       "      <td>-0.046947</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.666014</td>\n",
       "      <td>0.671985</td>\n",
       "      <td>0.246295</td>\n",
       "      <td>-0.105965</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.046809</td>\n",
       "      <td>0.231360</td>\n",
       "      <td>0.770618</td>\n",
       "      <td>-0.118048</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.600097</td>\n",
       "      <td>0.725136</td>\n",
       "      <td>0.066089</td>\n",
       "      <td>-0.036378</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.965995</td>\n",
       "      <td>0.861120</td>\n",
       "      <td>0.566829</td>\n",
       "      <td>-0.056758</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.165700</td>\n",
       "      <td>0.256856</td>\n",
       "      <td>0.654690</td>\n",
       "      <td>-0.128094</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.650996</td>\n",
       "      <td>0.424173</td>\n",
       "      <td>0.526744</td>\n",
       "      <td>-0.031039</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.106013</td>\n",
       "      <td>0.243332</td>\n",
       "      <td>0.650257</td>\n",
       "      <td>-0.117276</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.352164</td>\n",
       "      <td>0.105808</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>-0.079444</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.829086</td>\n",
       "      <td>0.439369</td>\n",
       "      <td>0.207134</td>\n",
       "      <td>-0.142586</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.804893</td>\n",
       "      <td>0.312070</td>\n",
       "      <td>0.243714</td>\n",
       "      <td>-0.119621</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.462041</td>\n",
       "      <td>0.129396</td>\n",
       "      <td>0.838586</td>\n",
       "      <td>-0.061199</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.822171</td>\n",
       "      <td>0.466507</td>\n",
       "      <td>0.549292</td>\n",
       "      <td>-0.034359</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.985148</td>\n",
       "      <td>0.720883</td>\n",
       "      <td>0.776440</td>\n",
       "      <td>-0.087697</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.186743</td>\n",
       "      <td>0.606741</td>\n",
       "      <td>0.669580</td>\n",
       "      <td>-0.115022</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.288103</td>\n",
       "      <td>0.702974</td>\n",
       "      <td>0.898496</td>\n",
       "      <td>-0.074789</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.087427</td>\n",
       "      <td>0.266736</td>\n",
       "      <td>0.301280</td>\n",
       "      <td>-0.104416</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.874361</td>\n",
       "      <td>0.867538</td>\n",
       "      <td>0.894363</td>\n",
       "      <td>-0.089455</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.703504</td>\n",
       "      <td>0.185323</td>\n",
       "      <td>0.819923</td>\n",
       "      <td>-0.087600</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.575798</td>\n",
       "      <td>0.322853</td>\n",
       "      <td>0.534177</td>\n",
       "      <td>-0.025146</td>\n",
       "      <td>initial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.856453</td>\n",
       "      <td>0.525792</td>\n",
       "      <td>0.668723</td>\n",
       "      <td>-0.122579</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.492462</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>-0.481918</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.517587</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>-0.495221</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>-0.506947</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.157188</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.918366</td>\n",
       "      <td>0.877555</td>\n",
       "      <td>-0.060329</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.196596</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085427</td>\n",
       "      <td>-0.100908</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170854</td>\n",
       "      <td>-0.182536</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>-0.172946</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.575295</td>\n",
       "      <td>0.322350</td>\n",
       "      <td>0.533675</td>\n",
       "      <td>-0.034982</td>\n",
       "      <td>query</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X_1       X_2       X_3         Y     Type\n",
       "0   0.171525  0.343917  0.248737 -0.112122  initial\n",
       "1   0.242114  0.644074  0.272433 -0.087963  initial\n",
       "2   0.534906  0.398501  0.173389 -0.111415  initial\n",
       "3   0.492581  0.611593  0.340176 -0.034835  initial\n",
       "4   0.134622  0.219917  0.458206 -0.048008  initial\n",
       "5   0.345523  0.941360  0.269363 -0.110621  initial\n",
       "6   0.151837  0.439991  0.990882 -0.398926  initial\n",
       "7   0.645503  0.397143  0.919771 -0.113869  initial\n",
       "8   0.746912  0.284196  0.226300 -0.131461  initial\n",
       "9   0.170477  0.697032  0.149169 -0.094190  initial\n",
       "10  0.220549  0.297825  0.343555 -0.046947  initial\n",
       "11  0.666014  0.671985  0.246295 -0.105965  initial\n",
       "12  0.046809  0.231360  0.770618 -0.118048  initial\n",
       "13  0.600097  0.725136  0.066089 -0.036378  initial\n",
       "14  0.965995  0.861120  0.566829 -0.056758  initial\n",
       "15  0.165700  0.256856  0.654690 -0.128094  initial\n",
       "16  0.650996  0.424173  0.526744 -0.031039  initial\n",
       "17  0.106013  0.243332  0.650257 -0.117276  initial\n",
       "18  0.352164  0.105808  0.065468 -0.079444  initial\n",
       "19  0.829086  0.439369  0.207134 -0.142586  initial\n",
       "20  0.804893  0.312070  0.243714 -0.119621  initial\n",
       "21  0.462041  0.129396  0.838586 -0.061199  initial\n",
       "22  0.822171  0.466507  0.549292 -0.034359  initial\n",
       "23  0.985148  0.720883  0.776440 -0.087697  initial\n",
       "24  0.186743  0.606741  0.669580 -0.115022  initial\n",
       "25  0.288103  0.702974  0.898496 -0.074789  initial\n",
       "26  0.087427  0.266736  0.301280 -0.104416  initial\n",
       "27  0.874361  0.867538  0.894363 -0.089455  initial\n",
       "28  0.703504  0.185323  0.819923 -0.087600  initial\n",
       "29  0.575798  0.322853  0.534177 -0.025146  initial\n",
       "30  0.856453  0.525792  0.668723 -0.122579    query\n",
       "31  0.492462  0.999999  0.999999 -0.481918    query\n",
       "32  0.517587  0.999999  0.999999 -0.495221    query\n",
       "33  0.999999  0.000000  0.999999 -0.506947    query\n",
       "34  0.999999  0.999999  0.000000 -0.157188    query\n",
       "35  0.226000  0.918366  0.877555 -0.060329    query\n",
       "36  0.000000  0.000000  0.000000 -0.196596    query\n",
       "37  0.000000  0.000000  0.085427 -0.100908    query\n",
       "38  0.000000  0.000000  0.170854 -0.182536    query\n",
       "39  0.000000  0.000000  0.256281 -0.172946    query\n",
       "40  0.575295  0.322350  0.533675 -0.034982    query"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_3.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b479c3",
   "metadata": {},
   "source": [
    "How did this whole thing evolve? Very simply at first. I didn't really know what I was doing on the ML algorithm side of things so I first wrote code to sweep through the inputs in each dimension and find the largest interval in that dimension that had not been sampled. I then cut that interval in half and sampled that point. repeat for each dimension.\n",
    "\n",
    "Then I wrote some code that actually performed BO using a class called BlackBoxFunction that imports and holds all the data for each function, and has methods to call for the data etc. I combined this with a BO algorithm using an RBF kernel and GaussianProcessRegressor. The main thing that I found challenging was the generation of the sample space in n-dimensions. i.e. for 1D you can simply call linspace(0,0.9999, 10000) to have an extremely densely packed space from which to sample (i.e. over which to build the surrogate. I created a function called make_mesh that took in the number of dimensions and required \"density\" of the space in order to generate n-dimensional meshes which I could use to generate the surrogate model. I quickly learned the difficulties of expanding to higher dimensions, as my make_mesh function relied on nested for loops that had extremely poor time complexity of O(n^D). As the dimensions D increased, the function became exponentially less efficient to compute the spaces. Thus, as the functions grew in dimension I had to severly limit the density at which each dimension could be sampled. As an example, for 2D functions I can get pack each of the dimensions with 1000 points, but this had to drop to 200 points per dimension in 3D, and down to 6 (!) points per dimension in 8D. I currently still sit with this problem, that I can truly not even begin to properly explore the space! I have thought of perhaps using another function to generate these n-dimensional meshes, analagous to the MATLAB function MESHGRID or NGRID. Indeed numpy itself has a function called meshgrid that I stumbled upon when searching for the MATLAB equivalent. Unfortunately, numpy's meshgrid seemed to suffer from the same curse of dimensionality.\n",
    "\n",
    "Initially I only calculated UCB for a couple weeks (after I built the above, ofc). Then added PI calculations as well such that I could compare the two manually to see the differences. UCB seemed to be very exploitative regardless of the value for B I gave it. Both models gave a problem that they would sometimes recommend the same points that have been previously queried! To help combat this I wrote some code to check if the new queries generated already existed in the data, such that I may know that I needed to do something to recify the issue.\n",
    "\n",
    "To help combat the repeated queries of the same points, I went back to the bayesian optimization notebook from week 12. I ran tests on known functions and identified that the model was again converging onto the same point repeatedly after just 13 iterations. This was happening on input intervals of [0,1] but not on larger intervals. In fact, the larger the interval the more iterations it took for the model to converge. This tipped me off to the length scale of the kernel. Having a tight input domain of [0,1] means that the length scale will have a larger effect. Reducing the length scale helped allieviate my problem of seeing the same repeated queries, though the problem was still there in a big way for the PI calculations. \n",
    "\n",
    "- Next up I will look into the possibility of using other kernels for the GP model\n",
    "- I will look deeper into the length scale to see if there are general heuristics that can help choose the scale, ideally in an automated way that will vary depending on the size of the dataset/the number of weeks/epochs that have passed. \n",
    "- Different length scales for different dimensions!\n",
    "\n",
    "\n",
    "### I think I identified a workflow error! I would load the previous queries and data in and have it exported to excel. But for some reason, that data was not being incorporated into function.data in that process. That meant that when making the predicitions, the model was just predicting the same values as the previus week as it thought that it hadn't made that prediction yet!\n",
    "\n",
    "### Function 5 predicted a big fish on interation 47! It will likely want to stay stuck there now since the others are so much smaller. \n",
    "\n",
    "# Maybe I need to generate local meshes around optima to deter the mdoels from getting stuck in higher dimensions where I have less dense dimensions?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
